{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba20af5-7d09-4c72-ae9e-5faf4d986ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering...\n",
      "Generating PCA-Cluster Features...\n",
      "Tuning KNN...\n",
      "Best KNN Score: 0.48691593305401987\n",
      "Best KNN Params: {'knn__n_neighbors': 15, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "Saved: submission_pure_knn_optimized.csv\n",
      "   participant_id personality_cluster\n",
      "0            1005           Cluster_E\n",
      "1             197           Cluster_C\n",
      "2            2343           Cluster_E\n",
      "3            1709           Cluster_A\n",
      "4             436           Cluster_E\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PowerTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA\n",
    "# ==========================================\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    # 1. Activity Score\n",
    "    df['activity_score'] = (df['hobby_engagement_level'] + \n",
    "                            df['physical_activity_index'] + \n",
    "                            df['creative_expression_index'])\n",
    "    # 2. Support Score\n",
    "    df['support_total'] = (df['support_environment_score'] + \n",
    "                           df['external_guidance_usage'] + \n",
    "                           df['upbringing_influence'])\n",
    "    # 3. Efficiency Ratios\n",
    "    df['efficiency'] = df['consistency_score'] / (df['focus_intensity'] + 1.0)\n",
    "    df['focus_per_support'] = df['focus_intensity'] / (df['support_environment_score'] + 1.0)\n",
    "    # 4. Age Norms\n",
    "    df['consistency_per_age'] = df['consistency_score'] / df['age_group']\n",
    "    return df\n",
    "\n",
    "print(\"Feature Engineering...\")\n",
    "train_eng = create_features(train)\n",
    "test_eng = create_features(test)\n",
    "\n",
    "# ==========================================\n",
    "# 3. PCA-GUIDED CLUSTERING\n",
    "# ==========================================\n",
    "print(\"Generating PCA-Cluster Features...\")\n",
    "\n",
    "full_data = pd.concat([train_eng.drop('personality_cluster', axis=1), test_eng], axis=0, ignore_index=True)\n",
    "\n",
    "# Features defining structure\n",
    "cluster_cols = ['focus_intensity', 'consistency_score', 'efficiency', 'activity_score', 'support_total', 'focus_per_support']\n",
    "scaler = StandardScaler()\n",
    "full_scaled = scaler.fit_transform(full_data[cluster_cols])\n",
    "\n",
    "# PCA to remove noise\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "full_pca = pca.fit_transform(full_scaled)\n",
    "\n",
    "# Cluster features (The \"GPS coordinates\" for KNN)\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=42, n_init=50)\n",
    "full_data['cluster_pca_5'] = kmeans_5.fit_predict(full_pca)\n",
    "\n",
    "kmeans_8 = KMeans(n_clusters=8, random_state=42, n_init=50)\n",
    "full_data['cluster_pca_8'] = kmeans_8.fit_predict(full_pca)\n",
    "\n",
    "# Split back\n",
    "train_eng['cluster_pca_5'] = full_data.iloc[:len(train)]['cluster_pca_5'].values\n",
    "train_eng['cluster_pca_8'] = full_data.iloc[:len(train)]['cluster_pca_8'].values\n",
    "test_eng['cluster_pca_5'] = full_data.iloc[len(train):]['cluster_pca_5'].values\n",
    "test_eng['cluster_pca_8'] = full_data.iloc[len(train):]['cluster_pca_8'].values\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREPROCESSING PIPELINE\n",
    "# ==========================================\n",
    "target_col = 'personality_cluster'\n",
    "X = train_eng.drop([target_col, 'participant_id'], axis=1)\n",
    "y = train_eng[target_col]\n",
    "X_test = test_eng.drop(['participant_id'], axis=1)\n",
    "\n",
    "nominal_cols = ['cultural_background', 'cluster_pca_5', 'cluster_pca_8']\n",
    "numeric_cols = [c for c in X.columns if c not in nominal_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('power', PowerTransformer(method='yeo-johnson')), # fixes skew\n",
    "    ('selector', SelectPercentile(f_classif, percentile=90)) # remove noise\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, nominal_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 5. OPTIMIZED PURE KNN\n",
    "# ==========================================\n",
    "# We use a Pipeline to prevent data leakage during GridSearch\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Tuning Grid:\n",
    "# 'weights': ['distance'] is usually better for high K\n",
    "# 'p': 1 (Manhattan) often works better on high-dimensional data than 2 (Euclidean)\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [15, 20, 25, 30, 35],\n",
    "    'knn__weights': ['distance'], \n",
    "    'knn__p': [1, 2] \n",
    "}\n",
    "\n",
    "print(\"Tuning KNN...\")\n",
    "grid = GridSearchCV(knn_pipeline, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(f\"Best KNN Score: {grid.best_score_}\")\n",
    "print(f\"Best KNN Params: {grid.best_params_}\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. SUBMISSION\n",
    "# ==========================================\n",
    "preds = grid.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'participant_id': test['participant_id'],\n",
    "    'personality_cluster': preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_pure_knn_optimized.csv', index=False)\n",
    "print(\"Saved: submission_pure_knn_optimized.csv\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef957250-d8f3-4582-9c79-5180f98b1bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
