{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf8eb7-21da-4338-909f-677c7d244ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering...\n",
      "Generating PCA-Cluster Features...\n",
      "Initializing Fixed Logistic Regression...\n",
      "Training Pure Logistic Model...\n",
      "Best Regularization Strength (C) Found: 0.3593813663804626\n",
      "Generating Predictions...\n",
      "SUCCESS! Pure Logistic Submission Saved: submission_pure_logistic_fixed.csv\n",
      "   participant_id personality_cluster\n",
      "0            1005           Cluster_D\n",
      "1             197           Cluster_C\n",
      "2            2343           Cluster_E\n",
      "3            1709           Cluster_A\n",
      "4             436           Cluster_E\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PowerTransformer, StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA\n",
    "# ==========================================\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Activity Score\n",
    "    df['activity_score'] = (df['hobby_engagement_level'] + \n",
    "                            df['physical_activity_index'] + \n",
    "                            df['creative_expression_index'])\n",
    "    \n",
    "    # 2. Support Score\n",
    "    df['support_total'] = (df['support_environment_score'] + \n",
    "                           df['external_guidance_usage'] + \n",
    "                           df['upbringing_influence'])\n",
    "    \n",
    "    # 3. Efficiency Ratios\n",
    "    df['efficiency'] = df['consistency_score'] / (df['focus_intensity'] + 1.0)\n",
    "    df['focus_per_support'] = df['focus_intensity'] / (df['support_environment_score'] + 1.0)\n",
    "    \n",
    "    # 4. Age Norms\n",
    "    df['consistency_per_age'] = df['consistency_score'] / df['age_group']\n",
    "\n",
    "    # 5. Simple Interaction\n",
    "    df['support_x_guidance'] = df['support_environment_score'] * df['external_guidance_usage']\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Feature Engineering...\")\n",
    "train_eng = create_features(train)\n",
    "test_eng = create_features(test)\n",
    "\n",
    "# ==========================================\n",
    "# 3. PCA-GUIDED CLUSTERING\n",
    "# ==========================================\n",
    "print(\"Generating PCA-Cluster Features...\")\n",
    "\n",
    "# Combine for structure learning\n",
    "full_data = pd.concat([train_eng.drop('personality_cluster', axis=1), test_eng], axis=0, ignore_index=True)\n",
    "\n",
    "# Select columns\n",
    "cluster_cols = ['focus_intensity', 'consistency_score', 'efficiency', 'activity_score', \n",
    "                'support_total', 'focus_per_support', 'support_x_guidance']\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "full_scaled = scaler.fit_transform(full_data[cluster_cols])\n",
    "\n",
    "# PCA (Keep 95% signal)\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "full_pca = pca.fit_transform(full_scaled)\n",
    "\n",
    "# Clustering\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=42, n_init=50)\n",
    "full_data['cluster_pca_5'] = kmeans_5.fit_predict(full_pca)\n",
    "\n",
    "kmeans_8 = KMeans(n_clusters=8, random_state=42, n_init=50)\n",
    "full_data['cluster_pca_8'] = kmeans_8.fit_predict(full_pca)\n",
    "\n",
    "# Split back\n",
    "train_eng['cluster_pca_5'] = full_data.iloc[:len(train)]['cluster_pca_5'].values\n",
    "train_eng['cluster_pca_8'] = full_data.iloc[:len(train)]['cluster_pca_8'].values\n",
    "test_eng['cluster_pca_5'] = full_data.iloc[len(train):]['cluster_pca_5'].values\n",
    "test_eng['cluster_pca_8'] = full_data.iloc[len(train):]['cluster_pca_8'].values\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREPROCESSING PIPELINE\n",
    "# ==========================================\n",
    "target_col = 'personality_cluster'\n",
    "X = train_eng.drop([target_col, 'participant_id'], axis=1)\n",
    "y = train_eng[target_col]\n",
    "X_test = test_eng.drop(['participant_id'], axis=1)\n",
    "\n",
    "nominal_cols = ['cultural_background', 'cluster_pca_5', 'cluster_pca_8']\n",
    "numeric_cols = [c for c in X.columns if c not in nominal_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('power', PowerTransformer(method='yeo-johnson')),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)), \n",
    "    ('scaler', StandardScaler()), \n",
    "    ('selector', SelectPercentile(f_classif, percentile=80)) \n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, nominal_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# ==========================================\n",
    "# 5. PURE LOGISTIC REGRESSION\n",
    "# ==========================================\n",
    "print(\"Initializing Fixed Logistic Regression...\")\n",
    "\n",
    "# Changed solver to 'lbfgs' (more robust for small data)\n",
    "# Increased max_iter to 10000 to STOP warnings\n",
    "# Using 'l2' penalty\n",
    "clf = LogisticRegressionCV(\n",
    "    Cs=10, \n",
    "    cv=5,  \n",
    "    penalty='l2', \n",
    "    solver='lbfgs',\n",
    "    scoring='f1_macro',\n",
    "    class_weight='balanced',\n",
    "    max_iter=10000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 6. TRAIN & PREDICT\n",
    "# ==========================================\n",
    "print(\"Training Pure Logistic Model...\")\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X, y_encoded)\n",
    "\n",
    "print(f\"Best Regularization Strength (C) Found: {clf.C_[0]}\")\n",
    "\n",
    "print(\"Generating Predictions...\")\n",
    "y_pred_encoded = model_pipeline.predict(X_test)\n",
    "y_pred_labels = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# ==========================================\n",
    "# 7. SUBMISSION\n",
    "# ==========================================\n",
    "submission = pd.DataFrame({\n",
    "    'participant_id': test['participant_id'],\n",
    "    'personality_cluster': y_pred_labels\n",
    "})\n",
    "\n",
    "filename = 'submission_pure_logistic_fixed.csv'\n",
    "submission.to_csv(filename, index=False)\n",
    "print(f\"SUCCESS! Pure Logistic Submission Saved: {filename}\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f842c-2aa1-483f-824b-216ea02ffdb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
