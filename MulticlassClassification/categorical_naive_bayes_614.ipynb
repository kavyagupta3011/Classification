{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07a7c5-55b3-4a6f-b289-9e7f06b0f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering...\n",
      "Generating PCA-Cluster Features...\n",
      "Preprocessing Data...\n",
      "Training CatBoost on Processed Data...\n",
      "0:\tlearn: 0.6753790\ttotal: 9.01ms\tremaining: 18s\n",
      "200:\tlearn: 0.7987454\ttotal: 780ms\tremaining: 6.98s\n",
      "400:\tlearn: 0.8395191\ttotal: 1.54s\tremaining: 6.15s\n",
      "600:\tlearn: 0.8672243\ttotal: 2.32s\tremaining: 5.39s\n",
      "800:\tlearn: 0.8902248\ttotal: 3.13s\tremaining: 4.68s\n",
      "1000:\tlearn: 0.9095661\ttotal: 3.88s\tremaining: 3.87s\n",
      "1200:\tlearn: 0.9231573\ttotal: 4.63s\tremaining: 3.08s\n",
      "1400:\tlearn: 0.9367486\ttotal: 5.45s\tremaining: 2.33s\n",
      "1600:\tlearn: 0.9487716\ttotal: 6.19s\tremaining: 1.54s\n",
      "1800:\tlearn: 0.9618400\ttotal: 6.98s\tremaining: 772ms\n",
      "1999:\tlearn: 0.9702039\ttotal: 7.73s\tremaining: 0us\n",
      "Generating Predictions...\n",
      "Saved: submission_catboost_pipeline.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PowerTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA\n",
    "# ==========================================\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Activity Score\n",
    "    df['activity_score'] = (df['hobby_engagement_level'] + \n",
    "                            df['physical_activity_index'] + \n",
    "                            df['creative_expression_index'])\n",
    "    \n",
    "    # 2. Support Score\n",
    "    df['support_total'] = (df['support_environment_score'] + \n",
    "                           df['external_guidance_usage'] + \n",
    "                           df['upbringing_influence'])\n",
    "    \n",
    "    # 3. Efficiency Ratios\n",
    "    df['efficiency'] = df['consistency_score'] / (df['focus_intensity'] + 1.0)\n",
    "    df['focus_per_support'] = df['focus_intensity'] / (df['support_environment_score'] + 1.0)\n",
    "    \n",
    "    # 4. Age Norms\n",
    "    df['consistency_per_age'] = df['consistency_score'] / df['age_group']\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Feature Engineering...\")\n",
    "train_eng = create_features(train)\n",
    "test_eng = create_features(test)\n",
    "\n",
    "# ==========================================\n",
    "# 3. PCA-GUIDED CLUSTERING\n",
    "# ==========================================\n",
    "print(\"Generating PCA-Cluster Features...\")\n",
    "\n",
    "full_data = pd.concat([train_eng.drop('personality_cluster', axis=1), test_eng], axis=0, ignore_index=True)\n",
    "\n",
    "cluster_cols = ['focus_intensity', 'consistency_score', 'efficiency', 'activity_score', 'support_total', 'focus_per_support']\n",
    "scaler = StandardScaler()\n",
    "full_scaled = scaler.fit_transform(full_data[cluster_cols])\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "full_pca = pca.fit_transform(full_scaled)\n",
    "\n",
    "# Clusters\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=42, n_init=50)\n",
    "full_data['cluster_pca_5'] = kmeans_5.fit_predict(full_pca)\n",
    "\n",
    "kmeans_8 = KMeans(n_clusters=8, random_state=42, n_init=50)\n",
    "full_data['cluster_pca_8'] = kmeans_8.fit_predict(full_pca)\n",
    "\n",
    "# Split back\n",
    "train_eng['cluster_pca_5'] = full_data.iloc[:len(train)]['cluster_pca_5'].values\n",
    "train_eng['cluster_pca_8'] = full_data.iloc[:len(train)]['cluster_pca_8'].values\n",
    "test_eng['cluster_pca_5'] = full_data.iloc[len(train):]['cluster_pca_5'].values\n",
    "test_eng['cluster_pca_8'] = full_data.iloc[len(train):]['cluster_pca_8'].values\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREPROCESSING PIPELINE\n",
    "# ==========================================\n",
    "target_col = 'personality_cluster'\n",
    "X = train_eng.drop([target_col, 'participant_id'], axis=1)\n",
    "y = train_eng[target_col]\n",
    "X_test = test_eng.drop(['participant_id'], axis=1)\n",
    "\n",
    "nominal_cols = ['cultural_background', 'cluster_pca_5', 'cluster_pca_8']\n",
    "numeric_cols = [c for c in X.columns if c not in nominal_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('power', PowerTransformer(method='yeo-johnson')), # Fixes skew\n",
    "    ('selector', SelectPercentile(f_classif, percentile=90)) # Removes noise\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # Back to OneHot\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, nominal_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Preprocessing Data...\")\n",
    "X_processed = preprocessor.fit_transform(X, y)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# ==========================================\n",
    "# 5. CATBOOST ON PROCESSED DATA\n",
    "# ==========================================\n",
    "print(\"Training CatBoost on Processed Data...\")\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.02, \n",
    "    depth=7,                # Slightly deeper than before since noise is reduced\n",
    "    l2_leaf_reg=3,          # Reduced reg since we selected top 90% features already\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='Accuracy',\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    "    allow_writing_files=False\n",
    ")\n",
    "\n",
    "model.fit(X_processed, y_encoded)\n",
    "\n",
    "# ==========================================\n",
    "# 6. SUBMISSION\n",
    "# ==========================================\n",
    "print(\"Generating Predictions...\")\n",
    "y_pred_encoded = model.predict(X_test_processed).flatten()\n",
    "y_pred_labels = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'participant_id': test['participant_id'],\n",
    "    'personality_cluster': y_pred_labels\n",
    "})\n",
    "\n",
    "filename = 'submission_catboost_pipeline.csv'\n",
    "submission.to_csv(filename, index=False)\n",
    "print(f\"Saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc4d94-ecad-42a6-9af1-b72194dee051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
