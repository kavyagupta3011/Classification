{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddf06ab-0035-4f64-b8be-7b84540c0f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training on Small Subset: 11922 samples (20%)\n",
      " Validating on Remaining:  47689 samples (80%)\n",
      "\n",
      " Training SVM on 20% data...\n",
      " Training NN on 20% data...\n",
      "\n",
      "==============================\n",
      "RESULTS (Trained on 20% Data)\n",
      "==============================\n",
      " SVM F1: 0.7488\n",
      " NN  F1: 0.6980\n",
      "\n",
      " Conclusion: SVM generalizes better with limited data.\n",
      "\n",
      " Generating Submission Files using test.csv...\n",
      "Saved: submission_svm_20percent.csv\n",
      "Saved: submission_nn_20percent.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import QuantileTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 1. LOAD DATA\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Encode target\n",
    "train[\"retention_status\"] = train[\"retention_status\"].map({\"Stayed\": 1, \"Left\": 0}).astype(int)\n",
    "\n",
    "# 2. FEATURE ENGINEERING \n",
    "for df in [train, test]:\n",
    "    df[\"years_since_founding\"] = df[\"years_since_founding\"].fillna(df[\"years_since_founding\"].median())\n",
    "    df[\"revenue_per_year\"] = df[\"monthly_revenue_generated\"] / (df[\"years_since_founding\"] + 1)\n",
    "    df[\"life_investment_ratio\"] = df[\"years_with_startup\"] / (df[\"founder_age\"] + 1)\n",
    "    df[\"log_revenue\"] = np.log1p(df[\"monthly_revenue_generated\"])\n",
    "\n",
    "TARGET = \"retention_status\"\n",
    "ID_COL = \"founder_id\"\n",
    "\n",
    "# Prepare X (Train) and X_test (Submission Data)\n",
    "X = train.drop(columns=[TARGET, ID_COL, \"founder_visibility\"])\n",
    "y = train[TARGET]\n",
    "X_test_submission = test.drop(columns=[ID_COL, \"founder_visibility\"])\n",
    "\n",
    "# 3. SPLIT: TRAIN ON 20%, TEST ON 80% (Internal Check)\n",
    "# We use train_size=0.2 to isolate just 20% for training the models\n",
    "X_small_train, X_large_val, y_small_train, y_large_val = train_test_split(\n",
    "    X, y, train_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\" Training on Small Subset: {X_small_train.shape[0]} samples (20%)\")\n",
    "print(f\" Validating on Remaining:  {X_large_val.shape[0]} samples (80%)\")\n",
    "\n",
    "# 4. PREPROCESSORS\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", QuantileTransformer(output_distribution=\"normal\", random_state=42)),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, X.select_dtypes(include=[\"number\"]).columns),\n",
    "    (\"cat\", categorical_transformer, X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns),\n",
    "])\n",
    "\n",
    "# 5. DEFINE MODELS\n",
    "\n",
    "# --- SVM (Better for small data usually) ---\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"nystroem\", Nystroem(kernel=\"rbf\", n_components=800, random_state=42)),\n",
    "    (\"svm\", LinearSVC(class_weight=\"balanced\", max_iter=5000, dual=False))\n",
    "])\n",
    "\n",
    "# --- Neural Network (Data hungry) ---\n",
    "nn_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"nn\", MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# 6. TRAIN & COMPARE (Internal)\n",
    "print(\"\\n Training SVM on 20% data...\")\n",
    "svm_pipeline.fit(X_small_train, y_small_train)\n",
    "svm_preds = svm_pipeline.predict(X_large_val)\n",
    "svm_f1 = f1_score(y_large_val, svm_preds)\n",
    "\n",
    "print(\" Training NN on 20% data...\")\n",
    "nn_pipeline.fit(X_small_train, y_small_train)\n",
    "nn_preds = nn_pipeline.predict(X_large_val)\n",
    "nn_f1 = f1_score(y_large_val, nn_preds)\n",
    "\n",
    "# 7. REPORT\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"RESULTS (Trained on 20% Data)\")\n",
    "print(\"=\"*30)\n",
    "print(f\" SVM F1: {svm_f1:.4f}\")\n",
    "print(f\" NN  F1: {nn_f1:.4f}\")\n",
    "\n",
    "if svm_f1 > nn_f1:\n",
    "    print(\"\\n Conclusion: SVM generalizes better with limited data.\")\n",
    "else:\n",
    "    print(\"\\n Conclusion: Neural Network managed to learn better despite limited data.\")\n",
    "\n",
    "# 8. GENERATE SUBMISSION FILES\n",
    "print(\"\\n Generating Submission Files using test.csv...\")\n",
    "\n",
    "# SVM Submission\n",
    "svm_test_preds = svm_pipeline.predict(X_test_submission)\n",
    "svm_labels = np.where(svm_test_preds == 1, \"Stayed\", \"Left\")\n",
    "pd.DataFrame({\n",
    "    \"founder_id\": test[\"founder_id\"], \n",
    "    \"retention_status\": svm_labels\n",
    "}).to_csv(\"submission_svm_20percent.csv\", index=False)\n",
    "print(\"Saved: submission_svm_20percent.csv\")\n",
    "\n",
    "# NN Submission\n",
    "nn_test_preds = nn_pipeline.predict(X_test_submission)\n",
    "nn_labels = np.where(nn_test_preds == 1, \"Stayed\", \"Left\")\n",
    "pd.DataFrame({\n",
    "    \"founder_id\": test[\"founder_id\"], \n",
    "    \"retention_status\": nn_labels\n",
    "}).to_csv(\"submission_nn_20percent.csv\", index=False)\n",
    "print(\"Saved: submission_nn_20percent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553d543-7eeb-4dd4-aff2-b6ee01ffaad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
